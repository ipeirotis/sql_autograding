{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ipeirotis/sql_autograding/blob/main/few_shot_trial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DnUJuLCwe4zM"
   },
   "outputs": [],
   "source": [
    "!pip install -q openai\n",
    "!pip install -q google-cloud-secret-manager\n",
    "!pip3 install -U -q PyMySQL sqlalchemy sql_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lmp5ZIh-XTjP"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "\n",
    "# Login using the account that has access to the Google project\n",
    "# in order to access the resources for the project\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CuwzTSINVU0q"
   },
   "outputs": [],
   "source": [
    "from google.cloud import secretmanager\n",
    "\n",
    "\n",
    "def access_secret_version(project_id, secret_id, version_id):\n",
    "    \"\"\"\n",
    "    Access the payload of the given secret version and return it.\n",
    "\n",
    "    Args:\n",
    "        project_id (str): Google Cloud project ID.\n",
    "        secret_id (str): ID of the secret to access.\n",
    "        version_id (str): ID of the version to access.\n",
    "    Returns:\n",
    "        str: The secret version's payload, or None if\n",
    "        the version does not exist.\n",
    "    \"\"\"\n",
    "    client = secretmanager.SecretManagerServiceClient()\n",
    "    name = f\"projects/{project_id}/secrets/{secret_id}/versions/{version_id}\"\n",
    "    response = client.access_secret_version(request={\"name\": name})\n",
    "    return response.payload.data.decode(\"UTF-8\")\n",
    "\n",
    "\n",
    "openai_key = access_secret_version(\"sql-autograding\", \"openai-gpt4-32k\", \"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N3g_P4GBYTtb"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cjKXNKZ8cG_I"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import io\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qG_N-6bgcfu7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gcsfs\n",
    "\n",
    "fs = gcsfs.GCSFileSystem(project=\"sql_autograding\")\n",
    "with fs.open(\"gs://sql_autograding/cleaned_response.csv\") as f:\n",
    "    data = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r_k0_JWtcfxX"
   },
   "outputs": [],
   "source": [
    "data = data.drop(columns=\"Unnamed: 0\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SD8X_zr3pfBX"
   },
   "source": [
    "## Table Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pSzebBQ9-Rqj"
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CsHX3CQF-5Hx"
   },
   "outputs": [],
   "source": [
    "db_list = [\n",
    "    \"flights\",\n",
    "    \"imdb\",\n",
    "    \"music\",\n",
    "    \"restaurants\",\n",
    "    \"facebook\",\n",
    "    \"northwind\",\n",
    "    \"collisions\",\n",
    "]\n",
    "\n",
    "\n",
    "def db_schema(db_name):\n",
    "    \"\"\"\n",
    "    Connects to a database and returns the schema of each table in the database.\n",
    "\n",
    "    The function connects to a specific database using SQLAlchemy. It then retrieves the list of tables in\n",
    "    the database and for each table, it queries the schema (i.e., the list of fields/columns) and stores it\n",
    "    in a dictionary. The function returns a list of such dictionaries, with each dictionary representing a table\n",
    "    and its corresponding schema.\n",
    "\n",
    "    Args:\n",
    "        db_name (str): The name of the database to connect to and retrieve schemas from.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, with each dictionary containing the name of a table as the key and a\n",
    "              list of its fields as the value.\n",
    "\n",
    "    Example:\n",
    "        >>> db_schema('flights')\n",
    "        {'m_airports': ['airport', 'state', 'state_name']},\n",
    "        {'m_ticket_prices': ['origin', 'dest', 'carrier', 'fare', 'fare_per_mile','passengers', 'distance']\n",
    "        ...\n",
    "        },\n",
    "    \"\"\"\n",
    "\n",
    "    student_password = access_secret_version(\n",
    "        \"sql-autograding\", \"db_student_password\", \"1\"\n",
    "    )\n",
    "\n",
    "    conn_string = (\n",
    "        \"mysql+pymysql://{user}:{password}@{host}/{db}?charset=utf8mb4\".format(\n",
    "            host=\"db.ipeirotis.org\",\n",
    "            user=\"student\",\n",
    "            password=student_password,\n",
    "            db=db_name,\n",
    "            encoding=\"utf8mb4\",\n",
    "        )\n",
    "    )\n",
    "    engine = create_engine(conn_string)\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        tables = pd.read_sql_query(sql=text(\"show tables\"), con=conn)\n",
    "        tables = tables.iloc[:, -1].tolist()\n",
    "\n",
    "        schema_list = []\n",
    "        for t in tables:\n",
    "            d = pd.read_sql_query(sql=text(f\"describe {t}\"), con=conn)\n",
    "            table_schema = {t: d.loc[:, \"Field\"].tolist()}\n",
    "            schema_list.append(table_schema)\n",
    "    return schema_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ocv2TQ7U-Rtz"
   },
   "outputs": [],
   "source": [
    "flights_schema = db_schema(\"flights\")\n",
    "imdb_schema = db_schema(\"imdb\")\n",
    "music_schema = db_schema(\"music\")\n",
    "restaurants_schema = db_schema(\"restaurants\")\n",
    "facebook_schema = db_schema(\"facebook\")\n",
    "northwind_schema = db_schema(\"northwind\")\n",
    "collisions_schema = db_schema(\"collisions\")\n",
    "\n",
    "print(facebook_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Km2nCEstFabH"
   },
   "outputs": [],
   "source": [
    "schema_mapping = {\n",
    "    \"flights\": flights_schema,\n",
    "    \"imdb\": imdb_schema,\n",
    "    \"music\": music_schema,\n",
    "    \"restaurants\": restaurants_schema,\n",
    "    \"facebook\": facebook_schema,\n",
    "    \"northwind\": northwind_schema,\n",
    "    \"collisions\": collisions_schema,\n",
    "    \"['northwind', 'flights']\": (northwind_schema, flights_schema),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LRCDc304ACQB"
   },
   "outputs": [],
   "source": [
    "# # print(schema_fun(['northwind', 'flights']))\n",
    "# import re\n",
    "# def convert_to_list(string):\n",
    "#     # Remove the square brackets and extra spaces\n",
    "#     cleaned_string = re.sub(r'\\[|\\]', '', string).strip()\n",
    "#     # Split the string into individual elements\n",
    "#     elements = [elem.strip() for elem in cleaned_string.split(',')]\n",
    "#     # Return the converted list\n",
    "#     return elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10Ewguzg_rhs"
   },
   "outputs": [],
   "source": [
    "# def schema_fun(db):\n",
    "#   if isinstance(db, list):\n",
    "#     # schema_list = []\n",
    "#     # for name in db:\n",
    "#     #   schema_list.append(db_schema(name))\n",
    "#     # return schema_list\n",
    "#     return [db_schema(name) for name in db]\n",
    "#   else:\n",
    "#     return db_schema(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c_dYEFof-RzR"
   },
   "outputs": [],
   "source": [
    "data[\"schema\"] = data[\"Database\"].map(schema_mapping)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VNQGwRJJ9jcB"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Create a function to clean up a single text string\n",
    "def clean_html_content(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    try:\n",
    "        soup = BeautifulSoup(text, \"html.parser\")\n",
    "        return soup.get_text()\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "\n",
    "# Apply the function to every text column in your DataFrame\n",
    "for col in data.columns:\n",
    "    if col in (\"Database\", \"schema\"):\n",
    "        continue\n",
    "    if data[col].dtype == object:  # if the column is a text column\n",
    "        data[col] = data[col].apply(clean_html_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RcQZQjkInp2e"
   },
   "outputs": [],
   "source": [
    "# data = data.replace('&nbsp;', ' ', regex=True)\n",
    "# data = data.replace('&#160;', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dvl9i8Lkk0fy"
   },
   "source": [
    "## Group questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FYzZlsa_lfV7"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6VPyCd7nlYjq"
   },
   "outputs": [],
   "source": [
    "# train_df, test_df = train_test_split(data, test_size=0.2, stratify=data['QuestionId'], random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_nKfyEjck3tG"
   },
   "outputs": [],
   "source": [
    "df = data[data[\"QuestionId\"] == \"5,119,721\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_MaXJLlyk3vo"
   },
   "outputs": [],
   "source": [
    "qids = df[\"QuestionId\"].unique()\n",
    "print(qids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hE_SIhzfcjO7"
   },
   "source": [
    "## Mega Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbr61YXmghK9"
   },
   "source": [
    "===============================\n",
    "\n",
    "a. We are working with the XXX database, which has the following tables:\n",
    "artist(id, first_name, last_name)\n",
    "album(id, artist_id, name)\n",
    "track....\n",
    "\n",
    "b. The request to the student is \"Fetch all the tracks for user X\"\n",
    "\n",
    "c. The model answer is ..... (note that we may have multiple correct\n",
    "answers, the model answer is just an example)\n",
    "\n",
    "d. The student answer was .....\n",
    "\n",
    "e. Previously, students have submitted these answers and got back\n",
    "these responses and grades:\n",
    "\n",
    "e1. submission: ..... , grade: ..... , feedback\n",
    "\n",
    "e2. submission: ..... , grade: ..... , feedback\n",
    "\n",
    "e3. submission: ..... , grade: ..... , feedback\n",
    "\n",
    "Please provide a grade and feedback for the student\n",
    "\n",
    "==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVDKUG96cf2C"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def generate_submissions_string(\n",
    "    train_df: pd.DataFrame, submission_size: int = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate a string that concatenates student submissions up to the given size.\n",
    "\n",
    "    Args:\n",
    "        train_df (pd.DataFrame): The DataFrame containing the training data.\n",
    "        submission_size (int, optional): The number of submissions to include in the string. If None, include all submissions.\n",
    "\n",
    "    Returns:\n",
    "        str: A string containing the concatenated submissions.\n",
    "    \"\"\"\n",
    "    submissions = \"\"\n",
    "    for i, row in train_df.iterrows():\n",
    "        if submission_size is not None and i >= submission_size:\n",
    "            break\n",
    "        submission = row[\"InputUserAnswer\"]\n",
    "        grade = row[\"Score\"]\n",
    "        full_grade = row[\"full_score\"]\n",
    "        feedback = row[\"feedback\"]\n",
    "        submissions += f\"e{i}. submission: {submission}, grade: {grade}/{full_grade}, feedback: {feedback} \\\\n\\\\n\"\n",
    "    return submissions\n",
    "\n",
    "\n",
    "def generate_mega_prompt_for_id(\n",
    "    df: pd.DataFrame, id: str, submission_size: int = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate a mega prompt for a specific QuestionId.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "        id (str): The QuestionId to generate the mega prompt for.\n",
    "        submission_size (int, optional): The number of submissions to include in the mega prompt. If None, include all submissions.\n",
    "\n",
    "    Returns:\n",
    "        str: The mega prompt.\n",
    "    \"\"\"\n",
    "    temp = df[df[\"QuestionId\"] == id]\n",
    "\n",
    "    # If there's only one row or less, return None or handle it in a special way\n",
    "    if len(temp) <= 1:\n",
    "        return None  # TODO: Check what to return in this scenario\n",
    "\n",
    "    # making test size 1\n",
    "    train_df, test_df = train_test_split(temp, test_size=1, random_state=1234)\n",
    "    train_df = train_df.reset_index()\n",
    "    test_df = test_df.reset_index()\n",
    "\n",
    "    submissions = generate_submissions_string(train_df, submission_size)\n",
    "\n",
    "    db = train_df.loc[0, \"Database\"]\n",
    "    tables = train_df.loc[0, \"schema\"]\n",
    "    question = train_df.loc[0, \"Question\"]\n",
    "    key = train_df.loc[0, \"AnswerKey\"]\n",
    "\n",
    "    test = test_df.loc[0, \"InputUserAnswer\"]\n",
    "\n",
    "    mega_p = f\"\"\"\n",
    "      a. We are working with the {db} database, which has the following tables: {tables}\n",
    "\n",
    "      b. The request to the student is \"{question}\"\n",
    "\n",
    "      c. The model answer is {key} (note that we may have multiple correct answers, the model answer is just an example)\n",
    "\n",
    "      d. The student answer was {test}\n",
    "\n",
    "      e. Previously, students have submitted these answers and got back these responses and grades: \\\\n{submissions}\n",
    "\n",
    "      Please provide a grade and feedback for the student\n",
    "      \"\"\"\n",
    "    return mega_p\n",
    "\n",
    "\n",
    "def generate_mega_prompts(\n",
    "    df: pd.DataFrame, submission_size: int = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate a DataFrame of mega prompts for each unique QuestionId in the given DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "        submission_size (int, optional): The number of submissions to include in each mega prompt. If None, include all submissions.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the mega prompts.\n",
    "    \"\"\"\n",
    "    # mega_df = pd.DataFrame(columns=['QuestionId', 'MegaPrompt'])\n",
    "    result = []\n",
    "    qids = df[\"QuestionId\"].unique()\n",
    "\n",
    "    for id in qids:\n",
    "        mega_p = generate_mega_prompt_for_id(df, id, submission_size)\n",
    "        new_row = {\"QuestionId\": id, \"MegaPrompt\": mega_p}\n",
    "        result.append(new_row)\n",
    "\n",
    "    mega_df = pd.DataFrame(result)\n",
    "\n",
    "    return mega_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-_5Yo5xcf4J"
   },
   "outputs": [],
   "source": [
    "# for all questions each with all submissions => new df\n",
    "mega_df_all = generate_mega_prompts(data)\n",
    "mega_df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xcq_a5aW615i"
   },
   "outputs": [],
   "source": [
    "print(mega_df_all.loc[0, \"MegaPrompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W_jNNYgi618-"
   },
   "outputs": [],
   "source": [
    "# select a specific question and control submission size\n",
    "df = data[data[\"QuestionId\"] == \"5,168,443\"]\n",
    "\n",
    "df0 = generate_mega_prompts(df, 0)\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ddURkonabgAC"
   },
   "outputs": [],
   "source": [
    "df5 = generate_mega_prompts(df, 5)\n",
    "df10 = generate_mega_prompts(df, 10)\n",
    "df20 = generate_mega_prompts(df, 20)\n",
    "df_all = generate_mega_prompts(df, len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Doc6Lv0co-8"
   },
   "source": [
    "## GPT4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWD3YE-sAnIK"
   },
   "outputs": [],
   "source": [
    "def GPT4_generation(prompt):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4-32k\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        n=1,\n",
    "        stream=False,\n",
    "        temperature=0.0,\n",
    "        max_tokens=600,\n",
    "        top_p=1.0,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0\n",
    "        # stop = [\"Q:\"]\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S5gy_zhlcfRa"
   },
   "outputs": [],
   "source": [
    "print(GPT4_generation(df0.loc[0, \"MegaPrompt\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0tRG8lnfxnt"
   },
   "outputs": [],
   "source": [
    "print(GPT4_generation(df5.loc[0, \"MegaPrompt\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lKcB4Zdm_MQ1"
   },
   "outputs": [],
   "source": [
    "print(GPT4_generation(df10.loc[0, \"MegaPrompt\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wjp4NLtn_MbC"
   },
   "outputs": [],
   "source": [
    "print(GPT4_generation(df20.loc[0, \"MegaPrompt\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JQI2MfL2fxwy"
   },
   "outputs": [],
   "source": [
    "print(GPT4_generation(df_all.loc[0, \"MegaPrompt\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F9CittlfJL5A"
   },
   "outputs": [],
   "source": [
    "def test_shots(qid, n):\n",
    "    df = data[data[\"QuestionId\"] == qid]\n",
    "    df_n = generate_mega_prompts(df, n)\n",
    "    # df_n.head()\n",
    "    print(f\"{n} submissions:\")\n",
    "    print(GPT4_generation(df_n.loc[0, \"MegaPrompt\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_R05vvSKe37"
   },
   "outputs": [],
   "source": [
    "for i in range(0, 21, 5):\n",
    "    test_shots(\"5,168,443\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62Q3jcByHJJR"
   },
   "outputs": [],
   "source": [
    "mega_df_all.shape\n",
    "mega_df_all.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QAMfy4Xm69NJ"
   },
   "outputs": [],
   "source": [
    "mega_df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jM-mH10F7Fmy"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kxuKag4IHgsH"
   },
   "outputs": [],
   "source": [
    "for i, p in tqdm(mega_df_all.iterrows()):\n",
    "    # print(i, len(p['MegaPrompt'].split()))\n",
    "    p[\"feedback\"] = GPT4_generation(p[\"MegaPrompt\"])\n",
    "\n",
    "mega_df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UxYM0VDu87bx"
   },
   "outputs": [],
   "source": [
    "mega_df_all[\"feedback\"] = mega_df_all[\"MegaPrompt\"].apply(GPT4_generation)\n",
    "mega_df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RRYWmXy2cf9X"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur0jal2dcgAJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
