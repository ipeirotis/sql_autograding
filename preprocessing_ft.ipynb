{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ipeirotis/sql_autograding/blob/main/preprocessing_ft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pd1yNAj1_e8H"
   },
   "outputs": [],
   "source": [
    "!pip install -q openai\n",
    "!pip install -q google-cloud-secret-manager\n",
    "!pip install -U PyMySQL sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mvtWjL-WtlX4"
   },
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "import pandas as pd\n",
    "import io\n",
    "import openai\n",
    "import os\n",
    "\n",
    "from google.cloud import secretmanager\n",
    "\n",
    "from google.colab import auth\n",
    "\n",
    "import requests\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tgSMZDnRr8wo"
   },
   "outputs": [],
   "source": [
    "# Login using the account that has access to the Google project\n",
    "# in order to access the resources for the project\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jorn9T80BzgS"
   },
   "outputs": [],
   "source": [
    "def access_secret_version(project_id, secret_id, version_id):\n",
    "    \"\"\"\n",
    "    Access the payload of the given secret version and return it.\n",
    "\n",
    "    Args:\n",
    "        project_id (str): Google Cloud project ID.\n",
    "        secret_id (str): ID of the secret to access.\n",
    "        version_id (str): ID of the version to access.\n",
    "    Returns:\n",
    "        str: The secret version's payload, or None if\n",
    "        the version does not exist.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = secretmanager.SecretManagerServiceClient()\n",
    "        name = f\"projects/{project_id}/secrets/{secret_id}/versions/{version_id}\"\n",
    "        response = client.access_secret_version(request={\"name\": name})\n",
    "        return response.payload.data.decode(\"UTF-8\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to access the secret version: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "openai_key = access_secret_version(\"sql-autograding\", \"openai-gpt4-32k\", \"3\")\n",
    "openai.api_key = openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3uASpahqoY2K"
   },
   "outputs": [],
   "source": [
    "URL = \"https://api.openai.com/v1/chat/completions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r8pybyjT-2jL"
   },
   "outputs": [],
   "source": [
    "grading = {\n",
    "    \"model\": \"gpt-4-32k\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"question: There are two relationships between Customer and Plan. Explain how they differ. \\n Key: The Responsible For relationship is an overall 1:M relationship between Customer and Plan. A Customer can be responsible for 0, 1, or many Plans yet any one Plan will be linked to only 1 Customer for responsibility purposes. The Belongs relationship is an overall M:M relationship that permits the linking of multiple customers to a single plan, as in the case of family members being part of a particular plan or different plans. Student answer: Each customer can have 0 to many plans. Each plan must have one responsible party, but may belong to more than one customer. Grade on student answer based on the question and answer key.\",\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 256,\n",
    "    \"temperature\": 0,\n",
    "}\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {openai_key}\"}\n",
    "\n",
    "response = requests.post(URL, headers=headers, json=grading, stream=False)\n",
    "if response.status_code != 200:\n",
    "    print(\n",
    "        f\"Request to OpenAI failed with status {response.status_code}, response: {response.content}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "awybK4_Bt5vq"
   },
   "outputs": [],
   "source": [
    "print(response.content)\n",
    "# print(response.choices.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yNT0q9XaPf49"
   },
   "outputs": [],
   "source": [
    "fs = gcsfs.GCSFileSystem(project=\"sql_autograding\")\n",
    "with fs.open(\"gs://sql_autograding/quiz_responses.csv\") as f:\n",
    "    data = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KY0-cyju8POl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BeZzy_-68PXV"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iI1XJpFlRbZ2"
   },
   "outputs": [],
   "source": [
    "# remove columns\n",
    "df = data.drop(columns=[\"QuestionAnswerTime\"])\n",
    "df = df[df[\"QuestionType\"] == \"Long Answer Question\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "akEYnaaBTdR4"
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=1234)\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gSq72EKGA3wh"
   },
   "outputs": [],
   "source": [
    "# Each quizid is associated with a specific database. Music, Flights, Northwind, Facebook\n",
    "# It will need a bit of manual work to assign each quizid to a database,\n",
    "# but it will not take long (the questions are the same across quizzes offered for different sessions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUTWawxSWgSo"
   },
   "source": [
    "## Create fine-tuning dataset for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_OfGNMkeNjfg"
   },
   "outputs": [],
   "source": [
    "# assign each quiz with its database in df\n",
    "# Module 4 Practice: Flights Database Questions - flights\n",
    "# Restaurants Database: Simple Practice Queries - restaurants\n",
    "\n",
    "\n",
    "def map_db(quiz):\n",
    "    if \"Assignment 6\" in quiz or \"Module 4 Practice: Flights\" in quiz:\n",
    "        return \"flights\"\n",
    "    elif \"Assignment 5\" in quiz:\n",
    "        return \"imdb\"  # ?\n",
    "    elif \"Assignment 4\" in quiz or \"Assignment 3\" in quiz or \"Assignment 2\" in quiz:\n",
    "        return \"music\"\n",
    "    elif \"Module 4\" in quiz or \"Module 3\" in quiz or \"Restaurants Database\" in quiz:\n",
    "        return \"restaurants\"\n",
    "    elif \"Module 2\" in quiz:\n",
    "        return [\"facebook\", \"restaurants\"]\n",
    "    elif \"Module 1\" in quiz:\n",
    "        return \"northwind\"\n",
    "    elif \"General Data Analytics Practice\" in quiz:\n",
    "        return \"collisions\"\n",
    "    elif \"Final Exam\" in quiz:\n",
    "        return [\"northwind\", \"flights\"]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "df[\"Database\"] = df[\"QuizName\"].apply(map_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rHBs2RxdoFJU"
   },
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BeAItkj2qyuT"
   },
   "source": [
    "### Connect to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_r1BdoXeq68L"
   },
   "outputs": [],
   "source": [
    "conn_string = \"mysql+pymysql://{user}:{password}@{host}/?charset=utf8\".format(\n",
    "    host=\"db.ipeirotis.org\", user=\"student\", password=\"dwdstudent2015\", encoding=\"utf-8\"\n",
    ")\n",
    "engine = create_engine(conn_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kVxqKvrrRW_"
   },
   "source": [
    "### Prompt and Message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4Zy3dt7EmdU"
   },
   "source": [
    "Prompt:\n",
    "In database XXX, we ask the question: “what is the average fare of the flights departing from each airport”?\n",
    "The student answered “SELECT …. FROM ….”\n",
    "The correct answer was “SELECT …. FROM ….”\n",
    "\n",
    "Message:\n",
    "The TA assigned the grade “8/10” points\n",
    "The feedback from the TA was “....”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ogo3F8DWnYh"
   },
   "outputs": [],
   "source": [
    "df[\"prompt\"] = (\n",
    "    \"In database \"\n",
    "    + df[\"Database\"].apply(lambda x: \" \".join(x))\n",
    "    + \", we ask the question:\\n\\n \"\n",
    "    + df[\"Question\"]\n",
    "    + \"\\n\\n The studednt answered:\\n \"\n",
    "    + df[\"InputUserAnswer\"]\n",
    "    + \"\\n\\n The correct answer was: \"\n",
    "    + df[\"AnswerKey\"]\n",
    ")\n",
    "df[\n",
    "    \"message\"\n",
    "] = \"The TA assigned the grade {s} points. The feedback from the TA was {feedback}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pidQbKuuviMs"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UI76hBjaWnWB"
   },
   "outputs": [],
   "source": [
    "# for i, row in df.iterrows():\n",
    "#   db = row.Database\n",
    "#   q = row.Question\n",
    "#   ans = row.InputUserAnswer\n",
    "#   key = row.AnswerKey\n",
    "#   prompt = f'In database {db}, we ask the question: {q} The studednt answered {ans} The correct answer was {key}'\n",
    "\n",
    "#   s = row.Score\n",
    "#   feedback = row.CommentleftonUserResponse\n",
    "#   # how to get the full score\n",
    "#   message = f'The TA assigned the grade {s} points. The feedback from the TA was {feedback}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydOjG4UJWnpt"
   },
   "source": [
    "## Submit the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j7On8FpZwHth"
   },
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eR7S33IxWtP4"
   },
   "outputs": [],
   "source": [
    "!openai api fine_tunes.create -t test.jsonl -m ada --suffix \"grader_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kB8sGZUqWtYw"
   },
   "outputs": [],
   "source": [
    "!openai tools fine_tunes.prepare_data -f grader_train.jsonl\n",
    "!openai tools fine_tunes.prepare_data -f grader_test.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wwqn2q4bgxEI"
   },
   "outputs": [],
   "source": [
    "!openai api fine_tunes.create -t \"grader/grader_train.jsonl\" -v \"grader/grader_test.jsonl\" --batch_size 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g37x96oJWtv5"
   },
   "source": [
    "## Use the fine-tuning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fWgoAlfWwTD"
   },
   "source": [
    "## Grade a question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbYC8nYFD7bt"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XhRCg8x1D6iM"
   },
   "outputs": [],
   "source": [
    "# We compare the grade assigned by GPT to the grade assigned by the TA.\n",
    "# We will probably need to examine things critically when there are disagreements, as the difference may be also due to the TA being incorrect.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
